{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "CSV file for the bitcoin price for the time period of 01.01.2012 10:01 until 13.04.2025 02:13."
   ],
   "id": "ec7d143b9dbfed64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile\n",
    "\n",
    "ZIP_PATH = \"data/zip/\"\n",
    "ZIP_NAME = \"bitcoin-historical-data.zip\"\n",
    "ZIP_FILE = os.path.join(ZIP_PATH, ZIP_NAME)\n",
    "\n",
    "RAW_PATH = \"data/raw/\"\n",
    "RAW_NAME = \"btcusd_1-min_data.csv\"\n",
    "RAW_FILE = os.path.join(RAW_PATH, RAW_NAME)\n",
    "\n",
    "# Validate folders exist\n",
    "os.makedirs(ZIP_PATH, exist_ok=True)\n",
    "os.makedirs(RAW_PATH, exist_ok=True)\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.dataset_download_files(\"mczielinski/bitcoin-historical-data\", path=ZIP_PATH)\n",
    "\n",
    "# Extract zip\n",
    "zip_file = ZipFile(ZIP_FILE)\n",
    "zip_file.extractall(path=RAW_PATH)\n",
    "\n",
    "# Remove zip\n",
    "os.remove(ZIP_FILE)"
   ],
   "id": "d3eb147f3f149dc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Process dataset\n",
    "\n",
    "import os\n",
    "import pytz\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "PROCESSED_PATH = \"data/processed/\"\n",
    "PROCESSED_NAME = \"btcusd_1-min_data_processed.csv\"\n",
    "PROCESSED_FILE = os.path.join(PROCESSED_PATH, PROCESSED_NAME)\n",
    "\n",
    "# Validate folders exist\n",
    "os.makedirs(PROCESSED_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to convert Unix timestamp to formatted datetime string\n",
    "def convert_timestamp(ts):\n",
    "    dt = datetime.fromtimestamp(float(ts), tz=pytz.UTC)\n",
    "    timezone_str = dt.strftime(\"%z\")\n",
    "    formatted_timezone = f\"{timezone_str[:3]}:{timezone_str[3:]}\"\n",
    "    return dt.strftime(\"%Y-%m-%d %H:%M:%S\") + formatted_timezone\n",
    "\n",
    "\n",
    "# Copy the original file to processed directory\n",
    "shutil.copy2(RAW_FILE, PROCESSED_FILE)\n",
    "\n",
    "# Convert Timestamp column to datetime format\n",
    "df = pd.read_csv(PROCESSED_FILE, low_memory=False)\n",
    "df[\"datetime\"] = df[\"Timestamp\"].apply(convert_timestamp)\n",
    "\n",
    "# Save the processed data\n",
    "df.to_csv(PROCESSED_FILE, index=False)"
   ],
   "id": "4a58b432fefd2266",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "PROCESSED_PATH = \"data/processed/\"\n",
    "PROCESSED_NAME = \"btcusd_1-min_data_processed.csv\"\n",
    "PROCESSED_FILE = os.path.join(PROCESSED_PATH, PROCESSED_NAME)\n",
    "\n",
    "df = pd.read_csv(PROCESSED_FILE)\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], unit=\"s\", utc=True)\n",
    "df.set_index(\"Timestamp\", inplace=True)\n",
    "df.drop(columns=[\"datetime\"], inplace=True)\n",
    "df.info()"
   ],
   "id": "5b973a7a82f433a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_missing_values(df, figsize=(12, 8)):\n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(2, 1, figsize=figsize)\n",
    "\n",
    "    # Heatmap of missing values\n",
    "    sns.heatmap(df.isna(), cmap=\"viridis\", yticklabels=False, cbar=False, ax=axes[0])\n",
    "    axes[0].set_title(\"Missing Values Heatmap\")\n",
    "    axes[0].set_xlabel(\"Variables\")\n",
    "    axes[0].set_ylabel(\"Observations\")\n",
    "\n",
    "    # Percentage of missing values per column\n",
    "    missing_percentage = df.isna().sum() / len(df) * 100\n",
    "    missing_percentage.sort_values(ascending=False).plot(kind=\"bar\", ax=axes[1])\n",
    "    axes[1].set_title(\"Percentage of Missing Values per Column\")\n",
    "    axes[1].set_xlabel(\"Columns\")\n",
    "    axes[1].set_ylabel(\"Percentage of Missing Values\")\n",
    "    axes[1].grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Space between subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary of missing values\n",
    "    missing_values = df.isna().sum()\n",
    "    missing_percent = missing_values / len(df) * 100\n",
    "    summary = pd.DataFrame(\n",
    "        {\"Missing Values\": missing_values, \"Percentage\": missing_percent}\n",
    "    )\n",
    "    # Only show columns with missing values\n",
    "    summary = summary[summary[\"Missing Values\"] > 0].sort_values(\n",
    "        \"Percentage\", ascending=False\n",
    "    )\n",
    "\n",
    "    if len(summary) > 0:\n",
    "        print(\"Missing Values Summary:\")\n",
    "        print(summary)\n",
    "    else:\n",
    "        print(\"No missing values found in the dataset.\")\n",
    "\n",
    "    return summary"
   ],
   "id": "1577ad2d472b25d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary = plot_missing_values(df)",
   "id": "19330c9b75d993fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pd.set_option(\"display.precision\", 2)\n",
    "df.describe()"
   ],
   "id": "ebbddf5cb8e70a53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Splitting Strategy\n",
    "\n",
    "For our time series, we'll split the dataset into three distinct segments:\n",
    "\n",
    "1. **Training Set (60%)**: The earliest portion of our chronological data used to train the model and establish patterns.\n",
    "\n",
    "2. **Validation Set (20%)**: The middle segment used to tune hyperparameters and prevent overfitting during the development phase.\n",
    "\n",
    "3. **Test Set (20%)**: The most recent data, kept completely separate until final evaluation to simulate real-world performance.\n",
    "\n",
    "This chronological splitting approach is crucial for financial time series data to prevent data leakage and maintain the temporal nature of the information."
   ],
   "id": "23502d53c5ef7757"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Chronological split with 60/20/20\n",
    "train_size = int(0.6 * len(df))\n",
    "valid_size = int(0.2 * len(df))\n",
    "\n",
    "# Split in chronological order\n",
    "train_data = df.iloc[:train_size]\n",
    "valid_data = df.iloc[train_size : train_size + valid_size]\n",
    "test_data = df.iloc[train_size + valid_size :]\n",
    "\n",
    "print(f\"Training set: {len(train_data)} entries\")\n",
    "print(f\"Validation set: {len(valid_data)} entries\")\n",
    "print(f\"Test set: {len(test_data)} entries\")\n",
    "\n",
    "# Check time ranges\n",
    "print(f\"Training set: {train_data.index.min()} to {train_data.index.max()}\")\n",
    "print(f\"Validation set: {valid_data.index.min()} to {valid_data.index.max()}\")\n",
    "print(f\"Test set: {test_data.index.min()} to {test_data.index.max()}\")\n",
    "\n",
    "# Saving the split data records\n",
    "train_data.to_csv(os.path.join(PROCESSED_PATH, \"train_data.csv\"))\n",
    "valid_data.to_csv(os.path.join(PROCESSED_PATH, \"validation_data.csv\"))\n",
    "test_data.to_csv(os.path.join(PROCESSED_PATH, \"test_data.csv\"))"
   ],
   "id": "b9b03faf43773f11",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
